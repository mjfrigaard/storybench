How to calculate a rolling average
================
Martin Frigaard

## Rolling averages

Rolling (or moving) averages are a way to reduce noise and smooth time
series data. This post will cover how to compute and visualize rolling
averages for the new confirmed cases and deaths from COVID-19 in the
United States.

## Packages

We’ll load the packages below for `ggplot2`, `geofacet`, and
`hrbrthemes` for dope graph themes.

``` r
library(ggpubr) # grid arrage
library(zoo) # moving averages        
library(tidyverse) # all tidyverse packages
library(plotly) # more plots
library(skimr) # summaries 
library(hrbrthemes) # themes for graphs
library(socviz) # %nin%
library(openintro) # 
library(geofacet) # 
library(usmap) # lat and long
library(socviz) # for %nin%
library(ggmap) # mapping
```

## The Johns Hopkins COVID data

The code block below imports the COVID-19 data from [the Center for
Systems Science and Engineering at the Johns Hopkins Whiting School of
Engineering](https://github.com/CSSEGISandData/COVID-19) using the
[`fs`](https://www.tidyverse.org/blog/2018/01/fs-1.0.0/) and
[`purrr`](https://purrr.tidyverse.org/) packages.

``` r
JHCovid19States <- readr::read_csv("https://raw.githubusercontent.com/mjfrigaard/storybench/master/drafts/data/jhsph/2020-06-22-JHCovid19States.csv")
```

    #>  Parsed with column specification:
    #>  cols(
    #>    state = col_character(),
    #>    last_update = col_datetime(format = ""),
    #>    lat = col_double(),
    #>    long = col_double(),
    #>    confirmed = col_double(),
    #>    deaths = col_double(),
    #>    recovered = col_double(),
    #>    active = col_double(),
    #>    fips = col_double(),
    #>    incident_rate = col_double(),
    #>    people_tested = col_double(),
    #>    people_hospitalized = col_double(),
    #>    mortality_rate = col_double(),
    #>    testing_rate = col_double(),
    #>    hospitalization_rate = col_double(),
    #>    date = col_date(format = ""),
    #>    month_abbr = col_character(),
    #>    day = col_double(),
    #>    state_abbr = col_character()
    #>  )

### Wrangling steps

All the steps for wrangling these data are in [this
gist.](https://gist.github.com/mjfrigaard/f19a550dfa1e08eaf2b70f7c9a2e3d13)

### State-level Johns Hopkins COVID data

We ended up with a data frame that has the following new columns.

`state` - us state  
`state_abbr` - abbreviated state name  
`month_abbr` - month for data reported (with abbreviation)  
`date` - `as_date()` version of `last_update`

``` r
utils::head(JHCovid19States)
```

    #>  # A tibble: 6 x 19
    #>    state last_update           lat   long confirmed deaths recovered active
    #>    <chr> <dttm>              <dbl>  <dbl>     <dbl>  <dbl>     <dbl>  <dbl>
    #>  1 Alab… 2020-04-12 23:18:15  32.3  -86.9      3563     93        NA   3470
    #>  2 Alas… 2020-04-12 23:18:15  61.4 -152.        272      8        66    264
    #>  3 Ariz… 2020-04-12 23:18:15  33.7 -111.       3542    115        NA   3427
    #>  4 Arka… 2020-04-12 23:18:15  35.0  -92.4      1280     27       367   1253
    #>  5 Cali… 2020-04-12 23:18:15  36.1 -120.      22795    640        NA  22155
    #>  6 Colo… 2020-04-12 23:18:15  39.1 -105.       7307    289        NA   7018
    #>  # … with 11 more variables: fips <dbl>, incident_rate <dbl>,
    #>  #   people_tested <dbl>, people_hospitalized <dbl>, mortality_rate <dbl>,
    #>  #   testing_rate <dbl>, hospitalization_rate <dbl>, date <date>,
    #>  #   month_abbr <chr>, day <dbl>, state_abbr <chr>

## Calculating rolling averages

Two states have [seen a rapid increase in their death
rates](https://www.nytimes.com/2020/06/20/world/coronavirus-updates.html).
We’re going to calculate and visualize the rolling averages for
cumulative deaths and new deaths in these states and compare them to the
other 48 states. To calculate a simple moving average (over 7 days), we
can use the `rollmean()` function from the [zoo
package.](https://cran.r-project.org/web/packages/zoo/index.html). This
function takes a `k`, which is an ’*integer width of the rolling
window.* The code below calculates a 3, 5, 7, 15, and 21-day rolling
average for the `deaths` from COVID in the US.

``` r
JHCovid19States <- JHCovid19States %>%
    dplyr::arrange(desc(state)) %>% 
    dplyr::group_by(state) %>% 
    dplyr::mutate(death_03da = zoo::rollmean(deaths, k = 3, fill = NA),
                  death_05da = zoo::rollmean(deaths, k = 5, fill = NA),
                  death_07da = zoo::rollmean(deaths, k = 7, fill = NA),
                  death_15da = zoo::rollmean(deaths, k = 15, fill = NA),
                  death_21da = zoo::rollmean(deaths, k = 21, fill = NA)) %>% 
  dplyr::ungroup()
```

Below is an example of this calculation for the state of Florida,

``` r
JHCovid19States %>% 
  dplyr::arrange(date) %>% 
  dplyr::filter(state == "Florida") %>% 
  dplyr::select(state,
                date,
                deaths,
                death_03da:death_07da) %>% 
  utils::head(7)
```

    #>  # A tibble: 7 x 6
    #>    state   date       deaths death_03da death_05da death_07da
    #>    <chr>   <date>      <dbl>      <dbl>      <dbl>      <dbl>
    #>  1 Florida 2020-04-12    461        NA         NA         NA 
    #>  2 Florida 2020-04-14    499       510.        NA         NA 
    #>  3 Florida 2020-04-14    571       555.       559         NA 
    #>  4 Florida 2020-04-15    596       612.       612.       610.
    #>  5 Florida 2020-04-16    668       663        662.       654.
    #>  6 Florida 2020-04-17    725       714.       702.       701.
    #>  7 Florida 2020-04-18    748       749        747.       743.

The calculation works like so,

  - the first value in our new `death_03da` variable (`510.3333`) is the
    average `deaths` in Florida from the first date with a data point on
    either side of it (i.e. the date `2020-04-13` has `2020-04-12`
    preceding it, and `2020-04-14` following it). We can check our math
    below.

<!-- end list -->

``` r
mean(c(461, 499, 571))
```

    #>  [1] 510.3333

  - the first value in `death_05da` (`132.0`) is the average `deaths` in
    Florida from the first date with **two** data points on either side
    of it (`2020-04-14` has `2020-04-12` and `2020-04-13` preceding it,
    and `2020-04-15` and `2020-04-16` following it). We can check our
    math below.

<!-- end list -->

``` r
mean(c(461, 499, 571, 596, 668))
```

    #>  [1] 559

  - And the first value in `death_07da` (`609.7143`) is the average
    death rate in Florida from the first date with three data points on
    either side (`2020-04-15` has `2020-04-12`, `2020-04-13` and
    `2020-04-14` preceding it, and `2020-04-16`, `2020-04-17`, and
    `2020-04-18` following it). Check our math again:

<!-- end list -->

``` r
mean(c(461, 499, 571, 596, 668, 725, 748))
```

    #>  [1] 609.7143

It’s good practice to calculate rolling averages using an odd number for
`k` (it makes the resulting values symmetrical).

<img src="figs/39-rolling-averages.png" width="1254" />

Each rolling mean is calculated from the numbers surrounding it. If we
want to visualize and compare the three rolling means against the
original `deaths` data, we can do this with a little `pivot_`ing,

``` r
gg_fl_death_avgs <- JHCovid19States %>% 
  dplyr::filter(state == "Florida") %>% 
  tidyr::pivot_longer(names_to = "rolling_mean_key", 
                    values_to = "rolling_mean_value", 
                    cols = c(deaths, 
                             death_03da, 
                             death_21da)) %>%
  dplyr::filter(date >= lubridate::as_date("2020-05-15") & # after may 15
                  date <= lubridate::as_date("2020-06-20")) %>% # before june 20
  ggplot2::ggplot(aes(x = date, 
                      y = rolling_mean_value, 
                      color = rolling_mean_key)) +
  ggplot2::geom_line() +   
  ggplot2::labs(title = "Florida's rolling average total COVID deaths", 
                  subtitle = "Between 2020-05-15 and 2020-06-20",
                  y = "Deaths", 
                  color = "Metric",
                  x = "Date") + 
  hrbrthemes::theme_ipsum_rc()
```

``` r
gg_sc_death_avgs <- JHCovid19States %>% 
  dplyr::filter(state == "South Carolina") %>% 
  tidyr::pivot_longer(names_to = "rolling_mean_key", 
                    values_to = "rolling_mean_value", 
                    cols = c(deaths, 
                             death_03da, 
                             death_21da)) %>%
  dplyr::filter(date >= lubridate::as_date("2020-05-15") & # after may 15
                  date <= lubridate::as_date("2020-06-20")) %>% # before june 20
  ggplot2::ggplot(aes(x = date, 
                      y = rolling_mean_value, 
                      color = rolling_mean_key)) +
  ggplot2::geom_line() +   
  ggplot2::labs(title = "South Carolina's rolling average total COVID deaths", 
                  subtitle = "Between 2020-05-15 and 2020-06-20",
                  y = "Deaths", 
                  color = "Metric",
                  x = "Date") + 
  hrbrthemes::theme_ipsum_rc()
```

<img src="figs/38-gg-fl-death-avgs.png" width="3264" />

<img src="figs/38-gg-sc-death-avgs.png" width="3264" />

## Which mean should I use?

The `zoo::rollmean()` function works by successively averaging each
period (`k`) together. Knowing which period (`k`) to use in
`zoo::rollmean()` is a judgment call. The higher the value of `k`, the
smoother the line gets, but are also sacrificing more data.

If we compare the 3-day average (`death_3da`) to the 21-day average
(`death_21da`), we see the line for `deaths` gets increasingly smooth.

## Calculating new cases in each state

Below we get some help from
[`dplyr::lag()`](https://dplyr.tidyverse.org/reference/lead-lag.html) to
calculate the new cases in each state per day.

We join this new calculation back to the `JHCovid19States` dataset, but
rename it `JHCovid19NewCases`.

``` r
JHCovid19NewCases <- JHCovid19States %>%
  # group this by state and day
  group_by(state, date) %>% 
  # get total deaths per day
  dplyr::summarize(
    confirmed_sum = (sum(confirmed, na.rm = TRUE))) %>% 
  # calculate 'new deaths' = todays deaths - yesterdays deaths
  mutate(new_confirmed_cases = confirmed_sum - dplyr::lag(x = confirmed_sum, n = 1, 
                                              order_by = date)) %>% 
  dplyr::select(state, 
                new_confirmed_cases, 
                date) %>% 
  # join back to JHCovid19
  dplyr::left_join(., y = JHCovid19States, 
                   by = c("state", "date")) %>% 
  # reorganize
  dplyr::select(state,
                state_abbr,
                date,
                month_abbr,
                day,
                confirmed,
                dplyr::contains("confirm"),
                dplyr::contains("death"),
                lat, 
                long, 
                dplyr::ends_with("rate"))
```

    #>  `summarise()` regrouping output by 'state' (override with `.groups` argument)

``` r
# check SC
JHCovid19NewCases %>% 
  dplyr::filter(state == "South Carolina") %>% 
  dplyr::select(state_abbr, date, confirmed, new_confirmed_cases) %>% 
  utils::head()
```

    #>  Adding missing grouping variables: `state`

    #>  # A tibble: 6 x 5
    #>    state          state_abbr date       confirmed new_confirmed_cases
    #>    <chr>          <chr>      <date>         <dbl>               <dbl>
    #>  1 South Carolina SC         2020-04-12      3320                  NA
    #>  2 South Carolina SC         2020-04-13      3391                  71
    #>  3 South Carolina SC         2020-04-14      3553                 162
    #>  4 South Carolina SC         2020-04-15      3656                 103
    #>  5 South Carolina SC         2020-04-16      3931                 275
    #>  6 South Carolina SC         2020-04-17      4099                 168

We can check this math below, too.

``` r
3391 - 3320 # 2020-04-13
```

    #>  [1] 71

``` r
3553 - 3391 # 2020-04-14
```

    #>  [1] 162

``` r
3656 - 3553  # 2020-04-15
```

    #>  [1] 103

``` r
3931 - 3656 # 2020-04-16
```

    #>  [1] 275

``` r
4099 - 3931  # 2020-04-17
```

    #>  [1] 168

We can see this calculation is getting the number of new confirmed cases
each day correct. Now we can calculate the rolling mean for the new
confirmed cases in each state.

``` r
JHCovid19NewCases <- JHCovid19NewCases %>%
    dplyr::group_by(state) %>% 
    dplyr::mutate(
      new_conf_03da = zoo::rollmean(new_confirmed_cases, k = 3, fill = NA),
      new_conf_05da = zoo::rollmean(new_confirmed_cases, k = 5, fill = NA),
      new_conf_07da = zoo::rollmean(new_confirmed_cases, k = 7, fill = NA),
      new_conf_15da = zoo::rollmean(new_confirmed_cases, k = 15, fill = NA),
      new_conf_21da = zoo::rollmean(new_confirmed_cases, k = 21, fill = NA)) %>% 
  dplyr::ungroup()
```

## Moving averages with geofacets

We’ll take a look at the seven-day moving averages of new cases across
all states using the [`geofacet`](https://hafen.github.io/geofacet/)
package. First we’ll build two plots for Florida, combine them, and then
extend this to the entire country.

### Column graph for new cases

First we will limit the `JHCovid19NewCases` data to June 1st - June
21st.

``` r
JHCovid19NewCasesJun <- JHCovid19NewCases %>% 
      dplyr::filter(date >= lubridate::as_date("2020-06-01") & # after june 1
                  date <= lubridate::as_date("2020-06-20")) # before june 20
```

This creates a
[`ggplot2::geom_col()`](https://ggplot2.tidyverse.org/reference/geom_bar.html)
for `new_confirmed_cases`.

We will build these two graphs with
[`hrbrthemes::theme_modern_rc()`](https://github.com/hrbrmstr/hrbrthemes).

``` r
JHCovid19NewCasesJun %>% 
  dplyr::filter(state == "Florida") %>% 
    ggplot2::ggplot(aes(x = day, 
                      y = new_confirmed_cases)) +
    geom_col(alpha = 1/10) + 
    ggplot2::labs(title = "Florida's new COVID cases", 
                  subtitle = "Rolling average between 2020-06-01 and 2020-06-20",
                  y = "New Cases", 
                  x = "Day") + 
  hrbrthemes::theme_modern_rc()
```

<img src="figs/38-gg_fl_new_cases_col.png" width="3264" />

### Create a tidy dataset of new cases

Now we want to add lines for the `new_conf_` variables, so this takes a
little wrangling.

``` r
FLNewCasesTidy <- JHCovid19NewCasesJun %>% 
  # only Florida
  dplyr::filter(state == "Florida") %>% 
  # pivot longer
  tidyr::pivot_longer(names_to = "new_conf_av_key", 
                    values_to = "new_conf_av_value", 
                    cols = c(new_conf_03da,
                             new_conf_05da,
                             new_conf_07da)) %>% 
  # reduce vars
  dplyr::select(day, 
                date, 
                state, 
                state_abbr, 
                new_conf_av_value, 
                new_conf_av_key)
head(FLNewCasesTidy)
```

    #>  # A tibble: 6 x 6
    #>      day date       state   state_abbr new_conf_av_value new_conf_av_key
    #>    <dbl> <date>     <chr>   <chr>                  <dbl> <chr>          
    #>  1     1 2020-06-01 Florida FL                      778. new_conf_03da  
    #>  2     1 2020-06-01 Florida FL                      832. new_conf_05da  
    #>  3     1 2020-06-01 Florida FL                      876. new_conf_07da  
    #>  4     2 2020-06-02 Florida FL                      674. new_conf_03da  
    #>  5     2 2020-06-02 Florida FL                      853. new_conf_05da  
    #>  6     2 2020-06-02 Florida FL                      985. new_conf_07da

Now we can combine them into a single plot.

``` r
JHCovid19NewCasesJun %>% 
  # florida new cases 
  dplyr::filter(state == "Florida") %>% 
    ggplot2::ggplot(aes(x = day, 
                      y = new_confirmed_cases, 
                      group(date))) +
    geom_col(alpha = 1/10) + 
  # add the line with new data
    ggplot2::geom_line(data = FLNewCasesTidy, 
                       mapping = aes(x = day, 
                                     y = new_conf_av_value, 
                                     color = new_conf_av_key)) +   
    ggplot2::labs(title = "Florida's new COVID cases", 
                  subtitle = "Rolling average between 2020-06-01 and 2020-06-20",
                  y = "New Cases", 
                  color = "Metric",
                  x = "Day") + 
    hrbrthemes::theme_modern_rc()
```

<img src="figs/38-gg_fl_new_cases_col-line.png" width="3264" />

We can see that the blue (7-day average) of new confirmed cases is
definitely the smoothest line. Let’s compare it to the 3-day average
using a `geofacet` for the other states in the US.

Again, we build our tidy data frame of new confirmed case metrics.

``` r
NewCasesTidy <- JHCovid19NewCasesJun %>% 
  # pivot longer
  tidyr::pivot_longer(names_to = "new_conf_av_key", 
                    values_to = "new_conf_av_value", 
                    cols = c(new_conf_03da,
                             new_conf_07da)) %>% 
    # better labels for printing
  dplyr::mutate(new_conf_av_key = dplyr::case_when(
    new_conf_av_key == "new_conf_03da" ~ "3-day new confirmed cases",
    new_conf_av_key == "new_conf_07da" ~ "7-day new confirmed cases",
    TRUE ~ NA_character_)) %>% 
  # reduce vars
  dplyr::select(day, 
                date, 
                state, 
                state_abbr, 
                new_conf_av_value, 
                new_conf_av_key)
head(NewCasesTidy)
```

    #>  # A tibble: 6 x 6
    #>      day date       state   state_abbr new_conf_av_value new_conf_av_key       
    #>    <dbl> <date>     <chr>   <chr>                  <dbl> <chr>                 
    #>  1     1 2020-06-01 Alabama AL                      533  3-day new confirmed c…
    #>  2     1 2020-06-01 Alabama AL                      403. 7-day new confirmed c…
    #>  3     2 2020-06-02 Alabama AL                      469  3-day new confirmed c…
    #>  4     2 2020-06-02 Alabama AL                      363. 7-day new confirmed c…
    #>  5     3 2020-06-03 Alabama AL                      300. 3-day new confirmed c…
    #>  6     3 2020-06-03 Alabama AL                      337. 7-day new confirmed c…

And we’ll switch the theme to
[`hrbrthemes::theme_ipsum_tw()`](https://hrbrmstr.github.io/hrbrthemes/).
We also use the `min` and `max` to get values for the `subtitle`

``` r
# get min and max for labels
min_date <- min(JHCovid19NewCasesJun$date, na.rm = TRUE)
max_date <- max(JHCovid19NewCasesJun$date, na.rm = TRUE)
JHCovid19NewCasesJun %>% 
    ggplot2::ggplot(aes(x = day, 
                      y = new_confirmed_cases)) +
    geom_col(alpha = 3/10, linetype = 0) + 
    ggplot2::geom_line(data = NewCasesTidy, 
                       mapping = aes(x = day, 
                                     y = new_conf_av_value, 
                                     color = new_conf_av_key)) +  
    geofacet::facet_geo( ~ state_abbr, 
                       grid = "us_state_grid2",
                       scales = "free_y")  +
    ggplot2::labs(title = "US rolling 3 and 7-day averages of new COVID cases", 
                  subtitle = "Between 2020-05-31 and 2020-06-20",
                  y = "New Cases",
                  color = "Metric:", 
                  x = "Day") + 
  hrbrthemes::theme_ipsum_tw() + 
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) + 
      ggplot2::theme(legend.position = "top")
```

<img src="figs/38-gg_facet_col_line_geo_new_conf.png" width="3264" />

This plot is a *little* misleading, because the `y` axis varies, but
we’re able to cram a lot of information into a single graphic (and see
some overall trends).

### More notes on rolling/moving averages:

  - “*A moving average term in a time series model is a past error
    (multiplied by a coefficient). Moving average is also used to smooth
    the series. It does this be removing noise from the time series by
    successively averaging terms together*” - [Machine Learning Using R:
    With Time Series and Industry-Based Use Cases in
    R](https://www.apress.com/gp/book/9781484242148)

  - [“*Moving averages is a smoothing approach that averages values from
    a window of consecutive time periods, thereby generating a series of
    averages. The moving average approaches primarily differ based on
    the number of values averaged, how the average is computed, and how
    many times averaging is
    performed*”](https://uc-r.github.io/ts_moving_averages).

  - [*"To compute the moving average of size k at a point p, the k
    values symmetric about p are averaged together which then replace
    the current value. The more points are considered for computing the
    moving average, the smoother the curve
    becomes.*"](http://www.feat.engineering/reducing-other-noise.html)
